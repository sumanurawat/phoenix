# Docker Container Execution Flow for Dataset Analysis

## ğŸ—ï¸ High-Level Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Phoenix Web   â”‚    â”‚  Iterative      â”‚    â”‚   Docker        â”‚
â”‚   Frontend      â”‚â”€â”€â”€â”€â”‚  Coding Agent   â”‚â”€â”€â”€â”€â”‚   Container     â”‚
â”‚                 â”‚    â”‚                 â”‚    â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                       â”‚
         â”‚                       â”‚                       â”‚
    User clicks              LLM generates           Executes code
   "Start Analysis"          Python code             securely
```

## ğŸ”„ Detailed Execution Sequence

### Phase 1: Request Initiation
```
Frontend (JavaScript)
â”œâ”€â”€ User clicks "Start Analysis"
â”œâ”€â”€ Sends POST to /api/datasets/analyze/step
â””â”€â”€ Includes: dataset_ref, model_config, description
```

### Phase 2: Agent Setup
```
Backend (Python)
â”œâ”€â”€ Creates EnhancedLLMService (Claude/Gemini)
â”œâ”€â”€ Initializes IterativeCodingAgent
â”œâ”€â”€ Enables conversation tracking
â””â”€â”€ Finds dataset files in temp directory
```

### Phase 3: Code Generation Loop
```
For each iteration (max 5):
â”œâ”€â”€ ğŸ¤– LLM generates Python code
â”œâ”€â”€ ğŸ“ Code logged to conversation
â”œâ”€â”€ ğŸ³ Execute in Docker container
â””â”€â”€ âŒ If failed â†’ retry with error context
```

## ğŸ³ Docker Container Execution Details

### Container Creation
```bash
# Docker command sequence:
docker create python:3.11-slim \
  --memory=512m \
  --cpu-quota=50000 \
  --network=none \
  --volume=/tmp/phoenix_xxxxx:/workspace

# Container gets:
Memory Limit: 512MB
CPU Limit: 50% of one core
Network: DISABLED (security)
Filesystem: Isolated + mounted data
```

### Inside Container Execution
```bash
# Step 1: Install dependencies
pip install --no-cache-dir pandas numpy matplotlib seaborn scipy scikit-learn

# Step 2: Change to workspace
cd /workspace

# Step 3: Execute generated code
python analysis_script.py
```

### Generated Script Structure
```python
# File: /workspace/analysis_script.py

# 1. Imports (auto-added)
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
# ... other imports

# 2. File variables (auto-added)
file_1 = 'dataset_file.csv'
main_file = file_1

# 3. User's generated code (wrapped in try-catch)
print("ğŸš€ Starting analysis execution...")
print("=" * 50)

try:
    # ğŸ¤– LLM-generated code goes here
    df = pd.read_csv(main_file)
    print(f"âœ… Data loaded successfully: {df.shape}")
    # ... rest of analysis code
    
    print("\n" + "=" * 50)
    print("ğŸ Analysis completed successfully!")
    print("=" * 50)
    
except Exception as e:
    print("\n" + "=" * 50)
    print("âŒ ANALYSIS EXECUTION FAILED")
    print("=" * 50)
    print(f"ğŸ“ Error Type: {type(e).__name__}")
    print(f"ğŸ’¬ Error Message: {str(e)}")
    
    # Debug information
    import traceback
    tb = traceback.extract_tb(e.__traceback__)
    if tb:
        print(f"ğŸ“ Error Line: {tb[-1].lineno}")
        print(f"ğŸ” Error Context: {tb[-1].line}")
    
    print("\nğŸ“š Full Traceback:")
    traceback.print_exc()
    
    print("\nğŸ”§ Debug Information:")
    print(f"ğŸ Python Version: {sys.version}")
    print(f"ğŸ“ Working Directory: {os.getcwd()}")
    print(f"ğŸ“‹ Available Files: {os.listdir('.')}")
    
    sys.exit(1)
```

## ğŸ“Š Output Collection

### Success Case
```
Container Exit Code: 0
STDOUT: All print statements, analysis results, charts info
STDERR: Warnings (if any)
Result: âœ… Code execution successful
```

### Failure Case
```
Container Exit Code: 1
STDOUT: Progress prints + error details
STDERR: Python traceback, import errors
Result: âŒ Send error to LLM for fixing
```

## ğŸ”„ Iteration & Error Handling

### Error Flow
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Code fails      â”‚
â”‚ Exit code = 1   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Collect error   â”‚
â”‚ STDERR output   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Send to LLM:    â”‚
â”‚ "Fix this error â”‚
â”‚ [error details]"â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Generate fixed  â”‚
â”‚ code version    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Create new      â”‚
â”‚ container &     â”‚
â”‚ try again       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ—‘ï¸ Cleanup Process

### After Each Execution
```bash
# Container cleanup
docker remove container_id --force

# Temp directory cleanup  
rm -rf /tmp/phoenix_docker_xxxxx/
```

### Resource Management
- Containers are ephemeral (created & destroyed per execution)
- No data persists between iterations
- Memory & CPU limits prevent resource exhaustion
- Network disabled prevents external access

## ğŸ’¬ Conversation Tracking

Every step is logged to the conversation panel:

```
ğŸ¤– User: "Generate code for: Load and explore dataset"
ğŸ“ System: "Executing code using ğŸ³ Docker Container"
âœ… AI: "```python\n[generated code]\n```\nâœ… Execution Result: [output]"
```

Or in case of error:

```
ğŸ¤– User: "Fix error: FileNotFoundError"  
ğŸ“ System: "Executing code using ğŸ³ Docker Container"
âŒ AI: "```python\n[fixed code]\n```\nâŒ Execution Failed: [error details]"
```

## ğŸ”’ Security Features

- **Network Isolation**: No internet access
- **Resource Limits**: Memory and CPU capped  
- **Filesystem Isolation**: Only sees mounted data
- **Process Isolation**: Cannot access host system
- **Temporary**: Containers destroyed after use

## ğŸ¯ Benefits

1. **Safety**: Untrusted LLM code runs isolated
2. **Consistency**: Same environment every time
3. **Scalability**: Easy to parallelize
4. **Debuggability**: Complete logs captured
5. **Reliability**: Failed containers don't affect system